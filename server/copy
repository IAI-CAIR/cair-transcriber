
from fastapi import FastAPI, File, UploadFile, Form
from fastapi.responses import StreamingResponse, JSONResponse
from fastapi.middleware.cors import CORSMiddleware
from faster_whisper import WhisperModel
import io
import json

app = FastAPI()

# Enable CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Initialize the Faster Whisper model
model_path = "./largev3"  # Adjust to your model path
model = WhisperModel(model_path, device="cuda", compute_type="int8_float16")

@app.get("/")
async def read_root():
    return {"message": "Welcome to the Cair Transcriber"}

def stream_transcription(audio_data: bytes, target_language: str = None):
    try:
        # Create an in-memory file-like object
        audio_file = io.BytesIO(audio_data)

        # Yield "Model loaded" info message
        yield json.dumps({
            "type": "info",
            "data": "Model loaded"
        })

        # Transcribe the audio with optional target language
        task = "transcribe"
        print(f"Transcribing with task: {task}, target language: {target_language}")
        segments, info = model.transcribe(
            audio_file,
            beam_size=5,
            task=task
        )

        # Yield language detection info
        yield json.dumps({
            "type": "language_detection",
            "data": info.language
        })

        # Yield each transcription segment
        for segment in segments:
            yield json.dumps({
                "start": segment.start,
                "end": segment.end,
                "text": segment.text
            })

    except Exception as e:
        yield json.dumps({
            "type": "error",
            "data": f"Error during transcription: {str(e)}"
        })
    finally:
        # Close the in-memory file
        audio_file.close()

@app.post("/transcribe")
async def transcribe_audio(
    file: UploadFile = File(...),
    target_language: str = Form(None)  # Optional target language
):
    try:
        # Read the file content into memory
        audio_data = await file.read()
        if len(audio_data) > 100_000_000:  # 100MB limit
            return JSONResponse(content={
                "type": "error",
                "data": "File size exceeds 100MB limit"
            }, status_code=400)

        # Return a streaming response
        return StreamingResponse(
            stream_transcription(audio_data, target_language),
            media_type="application/json"
        )

    except Exception as e:
        return JSONResponse(content={
            "type": "error",
            "data": f"Error during file upload: {str(e)}"
        }, status_code=500)

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)